# ChatBERT-IMR Small + SmolTalk
# Same as imr_small.yaml but with SmolTalk added to the data mix

model:
  name: "chatbert-imr-small-smoltalk"
  type: "iterative_mlm"

  backbone:
    pretrained: "distilbert-base-uncased"
    hidden_size: 768
    num_layers: 6
    num_attention_heads: 12
    intermediate_size: 3072

  vocab_size: 30522
  max_context_length: 256
  max_response_length: 64

  refinement:
    num_iterations: 10
    mask_schedule: "confidence"
    initial_mask_ratio: 1.0
    min_mask_ratio: 0.0
    temperature_schedule: "linear"
    initial_temperature: 1.0
    final_temperature: 0.1

training:
  datasets:
    - "daily_dialog"
    - "personachat"
    - "smoltalk"
  max_turns: 5

  mask_ratio_min: 0.15
  mask_ratio_max: 0.95

  epochs: 10
  batch_size: 32
  gradient_accumulation_steps: 1
  learning_rate: 5.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.1
  scheduler: "linear"
  fp16: true
  gradient_checkpointing: false
  logging_steps: 50
  eval_steps: 500
  save_steps: 1000
  early_stopping_patience: 15

inference:
  num_iterations: 15
  mask_schedule: "confidence"
  temperature: 0.5
  top_k: 10
